{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "class RC:\n",
    "    def __init__(self,\n",
    "                 N_input,\n",
    "                 N_hidden,\n",
    "                 N_output,\n",
    "                 alpha,\n",
    "                 ) -> None:\n",
    "        self.N_in = N_input\n",
    "        self.N_hid = N_hidden\n",
    "        self.N_out = N_output\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def reset(self,):\n",
    "        self.W_in = np.random.uniform(low=np.zeros((self.N_hid, self.N_in)), \n",
    "                                      high=np.ones((self.N_hid, self.N_in)))\n",
    "        self.A = np.random.uniform(low=np.zeros((self.N_hid, self.N_hid)), \n",
    "                                   high=np.ones((self.N_hid, self.N_hid)))\n",
    "        self.W_out = np.random.uniform(low=np.zeros((self.N_out, self.N_hid)), \n",
    "                                   high=np.ones((self.N_out, self.N_hid)))\n",
    "        self.r_history = np.zeros((self.N_hid, 1))\n",
    "        \n",
    "        \n",
    "    def activation(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        Ar = np.matmul(self.A, self.r_history)\n",
    "        U = np.matmul(self.W_in, x)\n",
    "        r = (1-self.alpha) * self.r_history + self.alpha * self.activation(Ar + U)\n",
    "        y = np.matmul(self.W_out, r)\n",
    "        self.r_history = r\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\ai\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: torch.Size([60000, 28, 28])\n",
      "tensor([[0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922],\n",
      "        [0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922],\n",
      "        [0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039],\n",
      "        [0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451]])\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.MNIST(root='./reservoir/data/',\n",
    "                                        train=True,\n",
    "                                        transform=None,\n",
    "                                        download=False,\n",
    "                                        )\n",
    "train_data = train.data.float()/255\n",
    "print('train shape:', train_data.shape)\n",
    "print(train_data[0][7:14,7:14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (train.data[0].float()/255 > torch.rand(train.data[0].size())).float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_dataset = torchvision.datasets.MNIST(root= './reservoir/data/', train=True, download=False, transform=None)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.98,  -0.59, -11.  ,  10.5 ,   1.44],\n",
       "       [ -2.02,  -0.28,   4.04,  -3.55,  -0.94],\n",
       "       [ -8.4 ,   1.7 ,   9.91,  -7.76,  -3.03],\n",
       "       [ -8.47,   1.53,  10.41, -10.63,  -0.96],\n",
       "       [ 10.53,  -2.08, -12.82,  12.39,   2.99]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(inv(np.random.rand(5, 5)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.13, 0.03, 0.14, 0.1 , 0.17, 0.11, 0.05, 0.16, 0.1 ],\n",
       "       [0.08, 0.11, 0.1 , 0.05, 0.07, 0.07, 0.17, 0.13, 0.07, 0.1 ],\n",
       "       [0.05, 0.13, 0.04, 0.09, 0.14, 0.14, 0.05, 0.14, 0.06, 0.12],\n",
       "       [0.11, 0.09, 0.05, 0.12, 0.11, 0.14, 0.07, 0.12, 0.04, 0.08],\n",
       "       [0.1 , 0.1 , 0.05, 0.1 , 0.11, 0.11, 0.16, 0.07, 0.07, 0.11]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import pinv\n",
    "from numpy.linalg import inv\n",
    "X = np.random.rand(5, 600)\n",
    "R = np.random.rand(10, 600)\n",
    "R_inv = np.matmul(R.T, inv(np.matmul(R, R.T) + 1e-8*np.eye(10)))\n",
    "np.round(np.matmul(X, R_inv),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.13, 0.03, 0.14, 0.1 , 0.17, 0.11, 0.05, 0.16, 0.1 ],\n",
       "       [0.08, 0.11, 0.1 , 0.05, 0.07, 0.07, 0.17, 0.13, 0.07, 0.1 ],\n",
       "       [0.05, 0.13, 0.04, 0.09, 0.14, 0.14, 0.05, 0.14, 0.06, 0.12],\n",
       "       [0.11, 0.09, 0.05, 0.12, 0.11, 0.14, 0.07, 0.12, 0.04, 0.08],\n",
       "       [0.1 , 0.1 , 0.05, 0.1 , 0.11, 0.11, 0.16, 0.07, 0.07, 0.11]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.matmul(X, pinv(R)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d39c09d048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC25JREFUeJzt3V+IpXd9x/H3p+lmg6sXCTZxG7eNlVAMga5l2BZSSkqIjUVIvDC4F7IFcb0wUMGLhr0xN4VQqjYXRVibxQ1oVNA0exGqIRRSoYRsQjDRtBrCVre77EYiGAvd/NlvL+asjJuZObPn33Nmv+8XLHPOM2fmfPOQ9zznzO+ceVJVSOrnt4YeQNIwjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpn57kXd2ZXbWVexa5F1Krfwf/8vrdS5bue1U8Se5A3gAuAL456q6f7PbX8Uu/iS3TXOXkjbxVD2x5dtO/LA/yRXAPwEfBm4C9ie5adLvJ2mxpnnOvw94qaperqrXgW8Ad85mLEnzNk381wM/W3P95Gjbb0hyMMnxJMff4NwUdydplqaJf71fKrzt/cFVdbiqVqpqZQc7p7g7SbM0TfwngT1rrr8XODXdOJIWZZr4nwZuTPK+JFcCHweOzWYsSfM28VJfVb2Z5B7gu6wu9R2pqh/ObDJJczXVOn9VPQY8NqNZJC2QL++VmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eamuosvUlOAK8BbwFvVtXKLIZSD9899dxUX/+Xv7t3RpP0NFX8I39RVT+fwfeRtEA+7Jeamjb+Ar6X5JkkB2cxkKTFmPZh/y1VdSrJtcDjSf6zqp5ce4PRD4WDAFfxjinvTtKsTHXkr6pTo49ngUeAfevc5nBVrVTVyg52TnN3kmZo4viT7EryrguXgQ8BL8xqMEnzNc3D/uuAR5Jc+D5fr6p/nclUkuZu4vir6mXgj2Y4iy5Dm63lu04/LJf6pKaMX2rK+KWmjF9qyvilpoxfamoW7+rTNjbubbXTLsfNczlv3rNf7jzyS00Zv9SU8UtNGb/UlPFLTRm/1JTxS025zt/cdl4L386zLwOP/FJTxi81ZfxSU8YvNWX8UlPGLzVl/FJTrvNfBrr+eexpTvF9Oe+XrfLILzVl/FJTxi81ZfxSU8YvNWX8UlPGLzU1dp0/yRHgI8DZqrp5tO0a4JvADcAJ4O6q+sX8xuzNv0+/vq7/3bOylSP/V4E7Ltp2L/BEVd0IPDG6LmkbGRt/VT0JvHrR5juBo6PLR4G7ZjyXpDmb9Dn/dVV1GmD08drZjSRpEeb+2v4kB4GDAFfxjnnfnaQtmvTIfybJboDRx7Mb3bCqDlfVSlWt7GDnhHcnadYmjf8YcGB0+QDw6GzGkbQoY+NP8jDwH8AfJjmZ5JPA/cDtSX4C3D66LmkbGfucv6r2b/Cp22Y8izYwbj276/v5x3G/bM5X+ElNGb/UlPFLTRm/1JTxS00Zv9SUf7p7G/Atvetzv0zHI7/UlPFLTRm/1JTxS00Zv9SU8UtNGb/UlOv8S8D16sm4X6bjkV9qyvilpoxfasr4paaMX2rK+KWmjF9qynX+JeB69WTGvT5iM+5zj/xSW8YvNWX8UlPGLzVl/FJTxi81ZfxSU2PX+ZMcAT4CnK2qm0fb7gM+BbwyutmhqnpsXkNe7qZZrwbXrDfiftncVo78XwXuWGf7l6pq7+if4UvbzNj4q+pJ4NUFzCJpgaZ5zn9Pkh8kOZLk6plNJGkhJo3/y8D7gb3AaeALG90wycEkx5Mcf4NzE96dpFmbKP6qOlNVb1XVeeArwL5Nbnu4qlaqamUHOyedU9KMTRR/kt1rrn4UeGE240halK0s9T0M3Aq8O8lJ4PPArUn2AgWcAD49xxklzcHY+Ktq/zqbH5zDLNIlcR1/Or7CT2rK+KWmjF9qyvilpoxfasr4pab8093atjy1+XQ88ktNGb/UlPFLTRm/1JTxS00Zv9SU8UtNuc6/BFyPXp/r+PPlkV9qyvilpoxfasr4paaMX2rK+KWmjF9qynX+JeB6tobgkV9qyvilpoxfasr4paaMX2rK+KWmjF9qauw6f5I9wEPAe4DzwOGqeiDJNcA3gRuAE8DdVfWL+Y16+Rq3ju/rADQPWznyvwl8rqo+APwp8JkkNwH3Ak9U1Y3AE6PrkraJsfFX1emqenZ0+TXgReB64E7g6OhmR4G75jWkpNm7pOf8SW4APgg8BVxXVadh9QcEcO2sh5M0P1uOP8k7gW8Dn62qX17C1x1McjzJ8Tc4N8mMkuZgS/En2cFq+F+rqu+MNp9Jsnv0+d3A2fW+tqoOV9VKVa3sYOcsZpY0A2PjTxLgQeDFqvrimk8dAw6MLh8AHp39eJLmZStv6b0F+ATwfJILa06HgPuBbyX5JPBT4GPzGVHjbLYUOPQy4Lhlys0MPfvlbmz8VfV9IBt8+rbZjiNpUXyFn9SU8UtNGb/UlPFLTRm/1JTxS035p7u3gWnf8jsk1+qXl0d+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnX+S9zQ78GwHX+5eWRX2rK+KWmjF9qyvilpoxfasr4paaMX2rKdf7LwDRr6dO+DsB1/O3LI7/UlPFLTRm/1JTxS00Zv9SU8UtNGb/U1Nh1/iR7gIeA9wDngcNV9UCS+4BPAa+Mbnqoqh6b16CaD9fp+9rKi3zeBD5XVc8meRfwTJLHR5/7UlX9w/zGkzQvY+OvqtPA6dHl15K8CFw/78EkzdclPedPcgPwQeCp0aZ7kvwgyZEkV2/wNQeTHE9y/A3OTTWspNnZcvxJ3gl8G/hsVf0S+DLwfmAvq48MvrDe11XV4apaqaqVHeycwciSZmFL8SfZwWr4X6uq7wBU1ZmqequqzgNfAfbNb0xJszY2/iQBHgRerKovrtm+e83NPgq8MPvxJM3LVn7bfwvwCeD5JBfe/3kI2J9kL1DACeDTc5lQ0lxs5bf93weyzqdc05e2MV/hJzVl/FJTxi81ZfxSU8YvNWX8UlPGLzVl/FJTxi81ZfxSU8YvNWX8UlPGLzVl/FJTqarF3VnyCvDfaza9G/j5wga4NMs627LOBc42qVnO9vtV9TtbueFC43/bnSfHq2plsAE2sayzLetc4GyTGmo2H/ZLTRm/1NTQ8R8e+P43s6yzLetc4GyTGmS2QZ/zSxrO0Ed+SQMZJP4kdyT5ryQvJbl3iBk2kuREkueTPJfk+MCzHElyNskLa7Zdk+TxJD8ZfVz3NGkDzXZfkv8Z7bvnkvzVQLPtSfJvSV5M8sMkfzPaPui+22SuQfbbwh/2J7kC+DFwO3ASeBrYX1U/WuggG0hyAlipqsHXhJP8OfAr4KGqunm07e+BV6vq/tEPzqur6m+XZLb7gF8Nfebm0Qlldq89szRwF/DXDLjvNpnrbgbYb0Mc+fcBL1XVy1X1OvAN4M4B5lh6VfUk8OpFm+8Ejo4uH2X1f56F22C2pVBVp6vq2dHl14ALZ5YedN9tMtcghoj/euBna66fZLlO+V3A95I8k+Tg0MOs47rRadMvnD792oHnudjYMzcv0kVnll6afTfJGa9nbYj41zv7zzItOdxSVX8MfBj4zOjhrbZmS2duXpR1ziy9FCY94/WsDRH/SWDPmuvvBU4NMMe6qurU6ONZ4BGW7+zDZy6cJHX08ezA8/zaMp25eb0zS7ME+26Zzng9RPxPAzcmeV+SK4GPA8cGmONtkuwa/SKGJLuAD7F8Zx8+BhwYXT4APDrgLL9hWc7cvNGZpRl43y3bGa8HeZHPaCnjH4ErgCNV9XcLH2IdSf6A1aM9rJ7E9OtDzpbkYeBWVt/1dQb4PPAvwLeA3wN+Cnysqhb+i7cNZruV1Yeuvz5z84Xn2Aue7c+AfweeB86PNh9i9fn1YPtuk7n2M8B+8xV+UlO+wk9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpv4fiZpcZGwgO7oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.distributions import Poisson, Uniform\n",
    "import torch\n",
    "\n",
    "p = Uniform(low=torch.zeros(28,28), high=torch.ones(28,28))\n",
    "img = p.sample()\n",
    "idx = img<=(train_data[1000]-0.5)\n",
    "img = torch.zeros_like(img)\n",
    "img[idx] = 1\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.flatten().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6333341fbbffcd56d5cc0c113aac57044b1e165b5c631658d7fce3237557af9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
